{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adversarial Training (Regularization) on a Recommender System\n",
    "\n",
    "_Source: ðŸ¤–[Adversarial Learning for Recommendation: Applications for Security and Generative Tasks â€“ Concept to Code](https://github.com/merrafelice/HandsOn-RecSys2020) repository_\n",
    "\n",
    "> Before moving on with this hands-on you might want to take a look at:\n",
    "> - ðŸ“— [Adversarial Machine Learning in Recommender Systems: State of the art and Challenges](https://arxiv.org/pdf/2005.10322.pdf)\n",
    "> - ðŸ“— [Adversarial Personalized Ranking for Recommendation](https://arxiv.org/pdf/1808.03908.pdf)\n",
    "\n",
    "**Adversarial training** (also **adversarial regularization**) is a defense strategy against adversarial perturbations.\n",
    "The main intuition is to increase the robustness of a recommender system on minimal adversarial perturbation of model parameters by adding further training iterations that takes into account the application of such perturbations.\n",
    "\n",
    "In this notebook, we become familiar with the usefulness of the adversarial regularization by:\n",
    "1. Training classical model-based recommender (BPR-MF[1]) on a small part of Movielens-1M\n",
    "2. Attacking the learned model with FGSM-like Adversarial Perturbations\n",
    "3. Adversarially Training the model-based recommender (BPR-MF) with Adversarial Personalized Ranking (APR[2])\n",
    "4. Attacking the robustified model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.util import timethis\n",
    "from src.recommender.Evaluator import Evaluator\n",
    "\n",
    "np.random.seed(25092020)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data\n",
    "First, we will load a short version of Movielens 1M dataset, which has been pre-processed and stored as a TSV file with the following structure: user_id, item_id, rating, timestamp.\n",
    "We have already divided the dataset in training and test sets using the leave-one-out evaluation protocol. We have used a small version with 500 users to reduce the computation time. To execute with the full dataset, you can change 'movielens-500' with 'movielens'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.dataset.dataset import DataLoader\n",
    "\n",
    "data = DataLoader(path_train_data='./data/movielens-500/trainingset.tsv'\n",
    "                      , path_test_data='./data/movielens-500/testset.tsv')\n",
    "\n",
    "print('Statistics:\\nNumber of Users: {0}\\nNumber of Items: {1}\\nTraining User-Item Ratings: {2}'.format(data.num_users, data.num_items, len(data.train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define The Model\n",
    "We will define a new Tensorflow 2 model class to define the model (BPR-MF). For a matter of simplicity we have also implemented the adversarial attack and defense strategies,, that will be used in the later sections."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from src.recommender.RecommenderModel import RecommenderModel\n",
    "\n",
    "TOPK = 100 # Top-K\n",
    "\n",
    "class BPRMF(RecommenderModel):\n",
    "    def __init__(self, data_loader, path_output_rec_result, path_output_rec_weight):\n",
    "        super(BPRMF, self).__init__(data_loader, path_output_rec_result, path_output_rec_weight, 'bprmf')\n",
    "        self.embedding_size = 64\n",
    "        self.learning_rate = 0.05\n",
    "        self.reg = 0\n",
    "        self.epochs = 5\n",
    "        self.batch_size = 512\n",
    "        self.verbose = 1\n",
    "        self.evaluator = Evaluator(self, data, TOPK)\n",
    "\n",
    "        self.initialize_model_parameters()\n",
    "        self.initialize_perturbations()\n",
    "        self.initialize_optimizer()\n",
    "\n",
    "    def initialize_model_parameters(self):\n",
    "        \"\"\"\n",
    "            Initialize Model Parameters\n",
    "        \"\"\"\n",
    "        self.embedding_P = tf.Variable(tf.random.truncated_normal(shape=[self.num_users, self.embedding_size], mean=0.0, stddev=0.01))  # (users, embedding_size)\n",
    "        self.embedding_Q = tf.Variable(tf.random.truncated_normal(shape=[self.num_items, self.embedding_size], mean=0.0, stddev=0.01))  # (items, embedding_size)\n",
    "        self.h = tf.constant(1.0, tf.float32, [self.embedding_size, 1])\n",
    "\n",
    "    def initialize_optimizer(self):\n",
    "        \"\"\"\n",
    "            Optimizer\n",
    "        \"\"\"\n",
    "        self.optimizer = tf.keras.optimizers.Adagrad(learning_rate=self.learning_rate)\n",
    "\n",
    "    def initialize_perturbations(self):\n",
    "        \"\"\"\n",
    "            Set delta variables useful to store delta perturbations,\n",
    "        \"\"\"\n",
    "        self.delta_P = tf.Variable(tf.zeros(shape=[self.num_users, self.embedding_size]), trainable=False)\n",
    "        self.delta_Q = tf.Variable(tf.zeros(shape=[self.num_items, self.embedding_size]), trainable=False)\n",
    "\n",
    "    def get_inference(self, user_input, item_input_pos):\n",
    "        \"\"\"\n",
    "            Generate Prediction Matrix with respect to passed users and items identifiers\n",
    "        \"\"\"\n",
    "        self.embedding_p = tf.reduce_sum(tf.nn.embedding_lookup(self.embedding_P + self.delta_P, user_input), 1)\n",
    "        self.embedding_q = tf.reduce_sum(tf.nn.embedding_lookup(self.embedding_Q + self.delta_Q, item_input_pos), 1)\n",
    "\n",
    "        return tf.matmul(self.embedding_p * self.embedding_q,self.h), self.embedding_p, self.embedding_q  # (b, embedding_size) * (embedding_size, 1)\n",
    "\n",
    "    def get_full_inference(self):\n",
    "        \"\"\"\n",
    "            Get Full Predictions useful for Full Store of Predictions\n",
    "        \"\"\"\n",
    "        return tf.matmul(self.embedding_P + self.delta_P, tf.transpose(self.embedding_Q + self.delta_Q))\n",
    "\n",
    "    @timethis\n",
    "    def _train_step(self, batches):\n",
    "        \"\"\"\n",
    "            Apply a Single Training Step (across all the batches in the dataset).\n",
    "        \"\"\"\n",
    "        user_input, item_input_pos, item_input_neg = batches\n",
    "\n",
    "        for batch_idx in range(len(user_input)):\n",
    "            with tf.GradientTape() as t:\n",
    "                t.watch([self.embedding_P, self.embedding_Q])\n",
    "\n",
    "                # Model Inference\n",
    "                self.output_pos, embed_p_pos, embed_q_pos = self.get_inference(user_input[batch_idx],\n",
    "                                                                               item_input_pos[batch_idx])\n",
    "                self.output_neg, embed_p_neg, embed_q_neg = self.get_inference(user_input[batch_idx],\n",
    "                                                                               item_input_neg[batch_idx])\n",
    "                self.result = tf.clip_by_value(self.output_pos - self.output_neg, -80.0, 1e8)\n",
    "\n",
    "                self.loss = tf.reduce_sum(tf.nn.softplus(-self.result))\n",
    "\n",
    "                # Regularization Component\n",
    "                self.reg_loss = self.reg * tf.reduce_mean(tf.square(embed_p_pos) + tf.square(embed_q_pos) + tf.square(embed_q_neg))\n",
    "\n",
    "                # Loss Function\n",
    "                self.loss_opt = self.loss + self.reg_loss\n",
    "\n",
    "            gradients = t.gradient(self.loss_opt, [self.embedding_P, self.embedding_Q])\n",
    "            self.optimizer.apply_gradients(zip(gradients, [self.embedding_P, self.embedding_Q]))\n",
    "\n",
    "    @timethis\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            batches = self.data.shuffle(self.batch_size)\n",
    "            self._train_step(batches)\n",
    "            print('Epoch {0}/{1}'.format(epoch+1, self.epochs))\n",
    "\n",
    "    @timethis\n",
    "    def _adversarial_train_step(self, batches, epsilon):\n",
    "        \"\"\"\n",
    "            Apply a Single Training Step (across all the batches in the dataset).\n",
    "        \"\"\"\n",
    "        user_input, item_input_pos, item_input_neg = batches\n",
    "        adv_reg = 1\n",
    "\n",
    "        for batch_idx in range(len(user_input)):\n",
    "            with tf.GradientTape() as t:\n",
    "                t.watch([self.embedding_P, self.embedding_Q])\n",
    "\n",
    "                # Model Inference\n",
    "                self.output_pos, embed_p_pos, embed_q_pos = self.get_inference(user_input[batch_idx],\n",
    "                                                                               item_input_pos[batch_idx])\n",
    "                self.output_neg, embed_p_neg, embed_q_neg = self.get_inference(user_input[batch_idx],\n",
    "                                                                               item_input_neg[batch_idx])\n",
    "                self.result = tf.clip_by_value(self.output_pos - self.output_neg, -80.0, 1e8)\n",
    "\n",
    "                self.loss = tf.reduce_sum(tf.nn.softplus(-self.result))\n",
    "\n",
    "                # Regularization Component\n",
    "                self.reg_loss = self.reg * tf.reduce_mean(tf.square(embed_p_pos) + tf.square(embed_q_pos) + tf.square(embed_q_neg))\n",
    "\n",
    "                # Adversarial Regularization Component\n",
    "                ##  Execute the Adversarial Attack on the Current Model (Perturb Model Parameters)\n",
    "                self.execute_adversarial_attack(epsilon)\n",
    "                ##  Inference on the Adversarial Perturbed Model\n",
    "                self.output_pos_adver, _, _ = self.get_inference(user_input[batch_idx], item_input_pos[batch_idx])\n",
    "                self.output_neg_adver, _, _ = self.get_inference(user_input[batch_idx], item_input_neg[batch_idx])\n",
    "\n",
    "                self.result_adver = tf.clip_by_value(self.output_pos_adver - self.output_neg_adver, -80.0, 1e8)\n",
    "                self.loss_adver = tf.reduce_sum(tf.nn.softplus(-self.result_adver))\n",
    "\n",
    "                # Loss Function\n",
    "                self.adversarial_regularizer = adv_reg * self.loss_adver # AMF = Adversarial Matrix Factorization\n",
    "                self.bprmf_loss = self.loss + self.reg_loss\n",
    "\n",
    "                self.amf_loss = self.bprmf_loss + self.adversarial_regularizer\n",
    "\n",
    "            gradients = t.gradient(self.amf_loss, [self.embedding_P, self.embedding_Q])\n",
    "            self.optimizer.apply_gradients(zip(gradients, [self.embedding_P, self.embedding_Q]))\n",
    "\n",
    "        self.initialize_perturbations()\n",
    "\n",
    "\n",
    "    @timethis\n",
    "    def adversarial_train(self, adversarial_epochs, epsilon):\n",
    "        for epoch in range(adversarial_epochs):\n",
    "            batches = self.data.shuffle(self.batch_size)\n",
    "            self._adversarial_train_step(batches, epsilon)\n",
    "            print('Epoch {0}/{1}'.format(self.epochs+epoch+1, self.epochs+adversarial_epochs))\n",
    "\n",
    "    def execute_adversarial_attack(self, epsilon):\n",
    "        user_input, item_input_pos, item_input_neg = self.data.shuffle(len(self.data._user_input))\n",
    "        self.initialize_perturbations()\n",
    "\n",
    "        with tf.GradientTape() as tape_adv:\n",
    "            tape_adv.watch([self.embedding_P, self.embedding_Q])\n",
    "            # Evaluate Current Model Inference\n",
    "            output_pos, embed_p_pos, embed_q_pos = self.get_inference(user_input[0],\n",
    "                                                                      item_input_pos[0])\n",
    "            output_neg, embed_p_neg, embed_q_neg = self.get_inference(user_input[0],\n",
    "                                                                      item_input_neg[0])\n",
    "            result = tf.clip_by_value(output_pos - output_neg, -80.0, 1e8)\n",
    "            loss = tf.reduce_sum(tf.nn.softplus(-result))\n",
    "            loss += self.reg * tf.reduce_mean(\n",
    "                tf.square(embed_p_pos) + tf.square(embed_q_pos) + tf.square(embed_q_neg))\n",
    "        # Evaluate the Gradient\n",
    "        grad_P, grad_Q = tape_adv.gradient(loss, [self.embedding_P, self.embedding_Q])\n",
    "        grad_P, grad_Q = tf.stop_gradient(grad_P), tf.stop_gradient(grad_Q)\n",
    "\n",
    "        # Use the Gradient to Build the Adversarial Perturbations (https://doi.org/10.1145/3209978.3209981)\n",
    "        self.delta_P = tf.nn.l2_normalize(grad_P, 1) * epsilon\n",
    "        self.delta_Q = tf.nn.l2_normalize(grad_Q, 1) * epsilon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize and Train The Model\n",
    "Now, we are ready to initialize and train the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommender_model = BPRMF(data, '../rec_result/', '../rec_weights/')\n",
    "recommender_model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate The Model\n",
    "The evaluation is computed on TOPK recommendation lists (default K = 100)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "before_adv_hr, before_adv_ndcg, before_adv_auc = recommender_model.evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adversarial Attack Against The Model\n",
    "We can attack the model with adversarial perturbation and measure the performance after the attack. Epsilon is the perturbation budget."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "print('Running the Attack with Epsilon = {0}'.format(epsilon))\n",
    "recommender_model.execute_adversarial_attack(epsilon=epsilon)\n",
    "print('The model has been Adversarially Perturbed.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the Effects of the Adversarial Attack\n",
    "We will now evaluate the performance of the attacked model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "after_adv_hr, after_adv_ndcg, after_adv_auc = recommender_model.evaluator.evaluate()\n",
    "\n",
    "print('HR decreases by %.2f%%' % ((1-after_adv_hr/before_adv_hr)*100))\n",
    "print('nDCG decreases by %.2f%%' % ((1-after_adv_ndcg/before_adv_ndcg)*100))\n",
    "print('AUC decreases by %.2f%%' % ((1-after_adv_auc/before_adv_auc)*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement The Adversarial Training/Regularization\n",
    "We have identified the clear performance degradation of the recommender under adversarial attack.\n",
    "Now, we can test whether the adversarial regularization will make the model more robust."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommender_model.adversarial_train(adversarial_epochs=1, epsilon=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluated The Adversarially Defended Model before the Attack"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "before_adv_hr, before_adv_ndcg, before_adv_auc = recommender_model.evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adversarial Attack Against The Defended Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommender_model.execute_adversarial_attack(epsilon=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the Effects of the Adversarial Attack against the Defended Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "after_adv_hr, after_adv_ndcg, after_adv_auc = recommender_model.evaluator.evaluate()\n",
    "\n",
    "print('HR decreases by %.2f%%' % ((1-after_adv_hr/before_adv_hr)*100))\n",
    "print('nDCG decreases by %.2f%%' % ((1-after_adv_ndcg/before_adv_ndcg)*100))\n",
    "print('AUC decreases by %.2f%%' % ((1-after_adv_auc/before_adv_auc)*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Consequences\n",
    "At this point, we have seen that the adversarial training has been effective in reducing the effectiveness of the FGSM-based adversarial attack against the recommender model.\n",
    "Furthermore, we have also identified another important consequences of the adversarial regularization. If we compare the performance of the model before and after the attack we can identify that there has been a performance improvement.\n",
    "For this reason, several recent works have implemented this robustification technique as an additional model component to increase the accuracy power of the recommender model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "1. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme: BPR: Bayesian Personalized Ranking from Implicit Feedback. UAI 2009: 452-461\n",
    "2. Xiangnan He, Zhankui He, Xiaoyu Du, Tat-Seng Chua: Adversarial Personalized Ranking for Recommendation. SIGIR 2018: 355-364\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}